{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba46e9e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            Version\n",
      "---------------------------------- -----------\n",
      "alembic                            1.16.4\n",
      "asttokens                          3.0.0\n",
      "blinker                            1.9.0\n",
      "cachetools                         5.5.2\n",
      "certifi                            2025.7.14\n",
      "charset-normalizer                 3.4.2\n",
      "click                              8.2.1\n",
      "cloudpickle                        3.1.1\n",
      "colorama                           0.4.6\n",
      "comm                               0.2.2\n",
      "contourpy                          1.3.2\n",
      "cycler                             0.12.1\n",
      "debugpy                            1.8.15\n",
      "decorator                          5.2.1\n",
      "docker                             7.1.0\n",
      "entrypoints                        0.4\n",
      "exceptiongroup                     1.3.0\n",
      "executing                          2.2.0\n",
      "Flask                              3.1.1\n",
      "fonttools                          4.59.0\n",
      "gitdb                              4.0.12\n",
      "GitPython                          3.1.44\n",
      "graphene                           3.4.3\n",
      "graphql-core                       3.2.6\n",
      "graphql-relay                      3.2.0\n",
      "greenlet                           3.2.3\n",
      "idna                               3.10\n",
      "importlib_metadata                 7.2.1\n",
      "ipykernel                          6.29.5\n",
      "ipython                            8.37.0\n",
      "itsdangerous                       2.2.0\n",
      "jedi                               0.19.2\n",
      "Jinja2                             3.1.6\n",
      "joblib                             1.5.1\n",
      "jupyter_client                     8.6.3\n",
      "jupyter_core                       5.8.1\n",
      "kiwisolver                         1.4.8\n",
      "Mako                               1.3.10\n",
      "Markdown                           3.8.2\n",
      "MarkupSafe                         3.0.2\n",
      "matplotlib                         3.10.3\n",
      "matplotlib-inline                  0.1.7\n",
      "mlflow                             2.14.0\n",
      "nest-asyncio                       1.6.0\n",
      "nltk                               3.9.1\n",
      "numpy                              1.26.4\n",
      "opentelemetry-api                  1.35.0\n",
      "opentelemetry-sdk                  1.35.0\n",
      "opentelemetry-semantic-conventions 0.56b0\n",
      "packaging                          24.2\n",
      "pandas                             2.3.1\n",
      "parso                              0.8.4\n",
      "pillow                             11.3.0\n",
      "pip                                25.1.1\n",
      "platformdirs                       4.3.8\n",
      "prompt_toolkit                     3.0.51\n",
      "protobuf                           4.25.8\n",
      "psutil                             7.0.0\n",
      "pure_eval                          0.2.3\n",
      "pyarrow                            15.0.2\n",
      "Pygments                           2.19.2\n",
      "pyparsing                          3.2.3\n",
      "python-dateutil                    2.9.0.post0\n",
      "pytz                               2024.2\n",
      "pywin32                            311\n",
      "PyYAML                             6.0.2\n",
      "pyzmq                              27.0.0\n",
      "querystring-parser                 1.2.4\n",
      "regex                              2024.11.6\n",
      "requests                           2.32.4\n",
      "scikit-learn                       1.7.0\n",
      "scipy                              1.15.3\n",
      "setuptools                         58.1.0\n",
      "six                                1.17.0\n",
      "smmap                              5.0.2\n",
      "SQLAlchemy                         2.0.41\n",
      "sqlparse                           0.5.3\n",
      "stack-data                         0.6.3\n",
      "threadpoolctl                      3.6.0\n",
      "tomli                              2.2.1\n",
      "tornado                            6.5.1\n",
      "tqdm                               4.67.1\n",
      "traitlets                          5.14.3\n",
      "typing_extensions                  4.14.1\n",
      "tzdata                             2025.2\n",
      "urllib3                            2.5.0\n",
      "waitress                           3.0.2\n",
      "wcwidth                            0.2.13\n",
      "Werkzeug                           3.1.3\n",
      "zipp                               3.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f79ed",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d524efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34578638",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a2e4a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/campusx-official/jupyter-masterclass/main/tweet_emotions.csv').drop(columns=['tweet_id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feef29c",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53192e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('Ø›', \"\")\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['content'] = df['content'].apply(lower_case)\n",
    "        df['content'] = df['content'].apply(remove_stop_words)\n",
    "        df['content'] = df['content'].apply(removing_numbers)\n",
    "        df['content'] = df['content'].apply(removing_punctuations)\n",
    "        df['content'] = df['content'].apply(removing_urls)\n",
    "        df['content'] = df['content'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d748b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>tiffanylue know listenin bad habit earlier sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed headache ughhhh waitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funeral ceremony gloomy friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>dannycastillo want trade someone houston ticke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  tiffanylue know listenin bad habit earlier sta...\n",
       "1     sadness            layin n bed headache ughhhh waitin call\n",
       "2     sadness                     funeral ceremony gloomy friday\n",
       "3  enthusiasm                              want hang friend soon\n",
       "4     neutral  dannycastillo want trade someone houston ticke..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0028b3",
   "metadata": {},
   "source": [
    "## Converting to binary classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e45b48f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "neutral       0.215950\n",
       "worry         0.211475\n",
       "happiness     0.130225\n",
       "sadness       0.129125\n",
       "love          0.096050\n",
       "surprise      0.054675\n",
       "fun           0.044400\n",
       "relief        0.038150\n",
       "hate          0.033075\n",
       "empty         0.020675\n",
       "enthusiasm    0.018975\n",
       "boredom       0.004475\n",
       "anger         0.002750\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "699f6336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10374, 2)\n",
      "sentiment\n",
      "1    5209\n",
      "0    5165\n",
      "Name: count, dtype: int64\n",
      "   sentiment                                            content\n",
      "1          0            layin n bed headache ughhhh waitin call\n",
      "2          0                     funeral ceremony gloomy friday\n",
      "6          0  sleep im not thinking old friend want married ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\THIS PC\\AppData\\Local\\Temp\\ipykernel_27348\\4258754123.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['sentiment'] = df['sentiment'].replace({'sadness':0,'happiness':1})\n"
     ]
    }
   ],
   "source": [
    "df = df[df['sentiment'].isin(['happiness','sadness'])]\n",
    "df['sentiment'] = df['sentiment'].replace({'sadness':0,'happiness':1})\n",
    "print(df.shape)\n",
    "print(df['sentiment'].value_counts())\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b38a5c8",
   "metadata": {},
   "source": [
    "## Apply Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12759fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 1000\n",
    "vectorizer = CountVectorizer(max_features=num_features)\n",
    "X = vectorizer.fit_transform(df['content'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bcc2b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "857e42e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8299, 1000)\n",
      "(8299,)\n",
      "(2075, 1000)\n",
      "(2075,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2133c7",
   "metadata": {},
   "source": [
    "## Dagshub Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bb2fa27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as datta-abhi\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as datta-abhi\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"datta-abhi/mlops-mini-project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"datta-abhi/mlops-mini-project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository datta-abhi/mlops-mini-project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository datta-abhi/mlops-mini-project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/17 11:46:38 INFO mlflow.tracking.fluent: Experiment with name 'BOW Logistic Baseline' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/3a327dc9a9cb46e08350cb0f110d7d58', creation_time=1752732998391, experiment_id='0', last_update_time=1752732998391, lifecycle_stage='active', name='BOW Logistic Baseline', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "dagshub.init(repo_owner='datta-abhi', repo_name='mlops-mini-project', mlflow=True)\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/datta-abhi/mlops-mini-project.mlflow\")\n",
    "\n",
    "mlflow.set_experiment(\"BOW Logistic Baseline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54402282",
   "metadata": {},
   "source": [
    "## MLflow runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dba88fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7773493975903615, 'precision': 0.7692307692307693, 'recall': 0.7783251231527094, 'f1': 0.7737512242899118}\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(description=\"simple BOW based Logistic baseline model to compare against\"):\n",
    "    # model building\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    # model evaluation\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    precision = precision_score(y_test,y_pred)    \n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    f1 = f1_score(y_test,y_pred)\n",
    "    \n",
    "    # log params\n",
    "    mlflow.log_params({\"vectorizer\":\"Bag of Words\",\n",
    "                       \"num_features\": num_features,\n",
    "                       \"test_size\":0.2,\n",
    "                       \"model\": \"Logistic\"})\n",
    "    \n",
    "    # log metrics\n",
    "    mlflow.log_metrics({\"accuracy\":accuracy,\n",
    "                        \"precision\": precision,\n",
    "                        \"recall\": recall,\n",
    "                        \"f1\": f1})\n",
    "    \n",
    "    # log notebook\n",
    "    import os\n",
    "    notebook_path = \"exp1_baseline_model.ipynb\"\n",
    "    os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "    mlflow.log_artifact(notebook_path)\n",
    "    \n",
    "    # log model\n",
    "    mlflow.sklearn.log_model(model,\"model\")\n",
    "    \n",
    "    # log tags\n",
    "    mlflow.set_tags({\"author\":\"Abhigyan\"})\n",
    "    \n",
    "    # print for checking\n",
    "    print({\"accuracy\":accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1})\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd8affc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570652d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
